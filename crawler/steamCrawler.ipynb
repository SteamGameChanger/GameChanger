{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import time\n",
        "from selenium import webdriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 반드시 확인!! 스팀 Kaggle 데이터 읽기  경로만 본인 환경에 맞게 재설정\n",
        "a_dataframe = pd.read_csv('C:/Users/raven/git/gameChanger-1/dataset/games.csv') \n",
        "# AppID 속성 추출한 데이터프레임 총 70210 개\n",
        "game_no = a_dataframe['AppID']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def saveGameData(gameIdx, gameCount):\n",
        "  savef = open(\"read.txt\",'w')\n",
        "  print(str(gameIdx))\n",
        "  savef.write(str(gameIdx)+','+str(gameCount)+'\\n')\n",
        "  savef.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# first_idx - 탐색 시작할 인덱스 번호  fileSave - 저장 횟수\n",
        "def start_crawling(first_idx, fileSave):\n",
        "  driver = webdriver.Chrome('C:\\\\Users\\raven\\git\\gameChanger-1\\WebDriver\\chromedriver.exe') # chromedriver 연결\n",
        "\n",
        "  for no in range(first_idx, len(game_no)+1):\n",
        "    result = []\n",
        "    ### URL 가져오기 시작 ###\n",
        "    url = 'https://store.steampowered.com/app/%d' %(int(game_no[no]))\n",
        "    print(url)\n",
        "    driver.get(url)\n",
        "    time.sleep(2)\n",
        "    html = urllib.request.urlopen(url)\n",
        "    driver.execute_script(\"window.scrollTo(0, 5000);\") # 스크롤 내린 상태로 Parsing 진행\n",
        "    time.sleep(10)\n",
        "    html = driver.page_source\n",
        "    SoupUrl = BeautifulSoup(html, 'html.parser')\n",
        "    ### URL 가져오기 끝 ###\n",
        "\n",
        "    tag_name_overall_reviews = SoupUrl.find('div', attrs={'id':'review_histogram_rollup_section'}) # Overall Reviews 정보\n",
        "    tag_name_recent_reviews = SoupUrl.find('div', attrs={'id':'review_histogram_recent_section'}) # Recent Reviews 정보\n",
        "\n",
        "    ### Overall Review 및 recent_review 데이터 추출 시작 ###\n",
        "    try:\n",
        "      overall_reviews = tag_name_overall_reviews.find('span', attrs={'class':'game_review_summary'})\n",
        "      overall_reviews = overall_reviews.get_text()\n",
        "\n",
        "      recent_reviews = tag_name_recent_reviews.find('span', attrs={'class':'game_review_summary'})\n",
        "      recent_reviews = recent_reviews.get_text()\n",
        "    except AttributeError as e:\n",
        "      print(\"Overall Review 또는 Recent Review 데이터가 없습니다.\")\n",
        "    ### Overall Review 및 recent_review 데이터 추출 끝 ###\n",
        "    ### metacritic URL 주소 추출 시작 ###\n",
        "    try:\n",
        "      metacritic_url = SoupUrl.find('div', attrs={'id':'game_area_metalink'})\n",
        "      metacritic_url = metacritic_url.find('a')['href']\n",
        "    except AttributeError as e:\n",
        "      print(\"Metacritic 링크가 존재하지 않습니다.\")\n",
        "    ### metacritic URL 주소 추출 끝 ###\n",
        "    ### 리뷰 부분 시작 ###\n",
        "    reviews_total = []\n",
        "    try:\n",
        "      # 리뷰있는 부분 찾기\n",
        "      tag_name_most_helpful_reviews = SoupUrl.find('div', attrs={'id':'Reviews_summary', 'class':'user_reviews_container'})    \n",
        "      most_helpful_reviews = tag_name_most_helpful_reviews.select(\"div>div.leftcol>div.review_box\")\n",
        "\n",
        "      for c_review in most_helpful_reviews:\n",
        "        rec = c_review.find(\"div\", attrs={'class':'title ellipsis'}).get_text() # 추천 or 비추천\n",
        "        content = c_review.find(\"div\", attrs={'class':'content'}).get_text() # 리뷰 내용\n",
        "\n",
        "        customer_review = rec + \", \"  + content\n",
        "        reviews_total.append(customer_review)\n",
        "    except AttributeError as e:\n",
        "      print(\"리뷰가 없습니다.\")\n",
        "    ### 리뷰 부분 종료 ###\n",
        "\n",
        "    steam_value = [overall_reviews] + [recent_reviews] + [metacritic_url] + [reviews_total]\n",
        "    print(steam_value)\n",
        "    result.append(steam_value)\n",
        "    Wcrawling_tbl = pd.DataFrame(result, columns=('Overall Reviews', 'Recent Reviews', 'Most Helpful Reviews', 'Currently popular'))\n",
        "    try:\n",
        "      Wcrawling_tbl.to_csv('C:/Users/raven/git/gameChanger-1/dataset/steamGameNo%d.csv' %(int(no)), encoding='UTF-8', mode='w', index=True)\n",
        "    except UnicodeEncodeError as e:\n",
        "      print(\"지원하지 않는 Unicode가 포함되어 있습니다.\", e)\n",
        "\n",
        "    saveGameData(no, fileSave)\n",
        "    fileSave += 1\n",
        "\n",
        "\n",
        "def main():\n",
        "  #초기 실행 이후 주석 해제\n",
        "  # f = open(\"read.txt\",'r')\n",
        "  # data = f.read()\n",
        "  # f.close()\n",
        "  # saveData = data.split(',')\n",
        "  # start_idx = int(saveData[0])\n",
        "  # fileSave = int(saveData[1])\n",
        "  #\n",
        "  \n",
        "  #초기 실행 이후 주석 처리\n",
        "  start_idx = 0\n",
        "  fileSave = 0\n",
        "  #\n",
        "  start_crawling(start_idx, fileSave)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
